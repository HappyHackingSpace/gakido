{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Gakido","text":"<p>High-performance CPython HTTP client with browser impersonation, HTTP/2, optional native fast-path, async support, and WebSockets.</p>"},{"location":"#quick-start","title":"Quick start","text":"<pre><code>from gakido import Client\n\nwith Client(impersonate=\"chrome_120\") as c:\n    r = c.get(\"https://example.com\")\n    print(r.status_code, r.text[:200])\n</code></pre>"},{"location":"#features","title":"Features","text":"<ul> <li>Browser profiles (Chrome/Firefox/Safari/Edge/Tor aliases)</li> <li>JA3/Akamai-like overrides via <code>tls_configuration_options</code></li> <li>HTTP/1.1 and HTTP/2 (ALPN) plus optional native HTTP fast-path</li> <li>Async client</li> <li>Streaming responses for large downloads</li> <li>Multipart uploads</li> <li>Retry with exponential backoff</li> <li>Minimal WebSocket client</li> </ul>"},{"location":"api/","title":"API Reference (essentials)","text":""},{"location":"api/#gakidoclient","title":"gakido.Client","text":"<ul> <li><code>Client(impersonate=\"chrome_120\", ja3=None, tls_configuration_options=None, proxies=None, timeout=10.0, verify=True, use_native=True, force_http1=True, auto_decompress=True, max_retries=0, retry_base_delay=1.0, retry_max_delay=60.0, retry_jitter=True)</code></li> <li>Methods: <code>get</code>, <code>post</code>, <code>request</code>, <code>close</code>, context manager.</li> <li><code>files</code> supported on <code>post</code>/<code>request</code> for multipart.</li> <li>proxies (<code>list[str] | None</code>): List of proxy URLs to rotate through. Supports HTTP, SOCKS5, and SOCKS5H schemes. Example: <code>[\"http://proxy:8080\", \"socks5://user:pass@proxy:1080\"]</code>. Default: <code>None</code>.</li> <li>max_retries (<code>int</code>): Maximum number of retry attempts (0 disables retry). Default: <code>0</code>.</li> <li>retry_base_delay (<code>float</code>): Initial delay in seconds for exponential backoff. Default: <code>1.0</code>.</li> <li>retry_max_delay (<code>float</code>): Maximum delay in seconds. Default: <code>60.0</code>.</li> <li>retry_jitter (<code>bool</code>): Whether to add random jitter to avoid thundering herd. Default: <code>True</code>.</li> </ul>"},{"location":"api/#gakidoaioasyncclient","title":"gakido.aio.AsyncClient","text":"<ul> <li><code>AsyncClient(impersonate=\"chrome_120\", timeout=10.0, verify=True, proxy_pool=None, ja3=None, tls_configuration_options=None, force_http1=True, http3=False, http3_fallback=True, auto_decompress=True, max_retries=0, retry_base_delay=1.0, retry_max_delay=60.0, retry_jitter=True)</code></li> <li>Async context manager; methods <code>get</code>, <code>post</code>, <code>request</code>, <code>close</code>.</li> <li>proxy_pool (<code>list[str] | None</code>): List of proxy URLs to rotate through. Supports HTTP, SOCKS5, and SOCKS5H schemes. Example: <code>[\"http://proxy:8080\", \"socks5://user:pass@proxy:1080\"]</code>. Default: <code>None</code>.</li> <li>max_retries (<code>int</code>): Maximum number of retry attempts (0 disables retry). Default: <code>0</code>.</li> <li>retry_base_delay (<code>float</code>): Initial delay in seconds for exponential backoff. Default: <code>1.0</code>.</li> <li>retry_max_delay (<code>float</code>): Maximum delay in seconds. Default: <code>60.0</code>.</li> <li>retry_jitter (<code>bool</code>): Whether to add random jitter to avoid thundering herd. Default: <code>True</code>.</li> </ul>"},{"location":"api/#compression-parameters","title":"Compression Parameters","text":"Parameter Type Default Description <code>auto_decompress</code> <code>bool</code> <code>True</code> Automatically decompress gzip/deflate/br responses <p>When <code>auto_decompress=True</code>: - Uses the profile's <code>Accept-Encoding</code> header (e.g., <code>gzip, deflate, br</code> for Chrome) - Automatically decompresses response bodies based on <code>Content-Encoding</code> - Supports gzip, deflate, and brotli (br) encodings</p> <p>When <code>auto_decompress=False</code>: - Sends <code>Accept-Encoding: identity</code> (no compression) - Returns raw, uncompressed response bodies</p>"},{"location":"api/#http3-parameters","title":"HTTP/3 Parameters","text":"Parameter Type Default Description <code>http3</code> <code>bool</code> <code>False</code> Enable HTTP/3 (QUIC) for compatible targets <code>http3_fallback</code> <code>bool</code> <code>True</code> Fall back to HTTP/1.1 or HTTP/2 if HTTP/3 fails <code>force_http3</code> <code>bool</code> <code>None</code> Per-request override (in <code>request()</code> method)"},{"location":"api/#gakidois_http3_available","title":"gakido.is_http3_available","text":"<ul> <li><code>is_http3_available() -&gt; bool</code></li> <li>Returns <code>True</code> if aioquic is installed and HTTP/3 support is available.</li> </ul>"},{"location":"api/#profiles","title":"Profiles","text":"<ul> <li><code>impersonate</code> accepts keys from <code>gakido.impersonation.PROFILES</code> (Chrome/Firefox/Safari/Edge/Tor aliases).</li> <li>Profiles include HTTP/3 settings (<code>http3.max_stream_data</code>, <code>http3.max_data</code>, <code>http3.idle_timeout</code>).</li> </ul>"},{"location":"api/#tls-overrides","title":"TLS overrides","text":"<ul> <li><code>ja3</code> dict: override ciphers/alpn/curves/sig_algs.</li> <li><code>tls_configuration_options</code>: accepts <code>ja3_str</code>, <code>akamai_str</code>, <code>extra_fp</code> (<code>ExtraFingerprints</code>).</li> </ul>"},{"location":"api/#websocket","title":"WebSocket","text":"<ul> <li><code>gakido.websocket.WebSocket.connect(host, port, resource, headers, tls, timeout)</code></li> <li>Methods: <code>send_text</code>, <code>send_bytes</code>, <code>recv</code>, <code>close</code>.</li> </ul>"},{"location":"api/#installation-extras","title":"Installation Extras","text":"<pre><code>pip install gakido          # Core package\npip install gakido[h3]      # With HTTP/3 (QUIC) support\npip install gakido[dev]     # Development dependencies\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<ul> <li>Run <code>pre-commit run --all-files</code> before pushing.</li> <li>Build docs: <code>make docs</code> (or <code>make docs-serve</code>).</li> <li>Tests: <code>make test</code>.</li> <li>Lint/format: <code>make lint</code> (ruff + ty).</li> <li>Native extension: built from <code>gakido/core.c</code> as <code>gakido_core</code> via <code>uv pip install -e .</code>.</li> </ul>"},{"location":"rate-limiting/","title":"Rate Limiting","text":"<p>gakido provides built-in rate limiting to control request throughput and avoid overwhelming servers or hitting API rate limits.</p>"},{"location":"rate-limiting/#features","title":"Features","text":"<ul> <li>Token bucket algorithm for smooth rate limiting with burst support</li> <li>Sliding window limiter for strict request count limits</li> <li>Per-host rate limiting to apply separate limits per domain</li> <li>Blocking and non-blocking modes - wait for capacity or raise exception</li> <li>Works with both sync and async clients</li> <li>Zero overhead when disabled (default)</li> </ul>"},{"location":"rate-limiting/#basic-usage","title":"Basic Usage","text":""},{"location":"rate-limiting/#sync-client","title":"Sync Client","text":"<pre><code>from gakido import Client\n\nclient = Client(\n    rate_limit=10.0,           # 10 requests per second globally\n    rate_limit_capacity=20.0,  # Allow burst of 20 requests\n    rate_limit_blocking=True,  # Wait when rate limited (default)\n)\n\n# Requests will be automatically rate limited\nfor i in range(100):\n    response = client.get(\"http://api.example.com/data\")\n    print(f\"Request {i}: {response.status_code}\")\n</code></pre>"},{"location":"rate-limiting/#async-client","title":"Async Client","text":"<pre><code>import asyncio\nfrom gakido import AsyncClient\n\nasync def main():\n    client = AsyncClient(\n        rate_limit=5.0,            # 5 requests per second\n        rate_limit_capacity=10.0,  # Allow burst of 10 requests\n    )\n\n    async with client:\n        tasks = [client.get(\"http://api.example.com/data\") for _ in range(50)]\n        responses = await asyncio.gather(*tasks)\n        print(f\"Completed {len(responses)} requests\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"rate-limiting/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>rate_limit</code> <code>float \\| None</code> <code>None</code> Global rate limit (requests per second), None to disable <code>rate_limit_capacity</code> <code>float \\| None</code> <code>None</code> Burst capacity (defaults to rate_limit) <code>rate_limit_per_host</code> <code>float \\| None</code> <code>None</code> Per-host rate limit (requests per second) <code>rate_limit_blocking</code> <code>bool</code> <code>True</code> If True, wait when rate limited; if False, raise RateLimitExceeded"},{"location":"rate-limiting/#per-host-rate-limiting","title":"Per-Host Rate Limiting","text":"<p>Apply separate rate limits to each domain:</p> <pre><code>from gakido import Client\n\nclient = Client(\n    rate_limit_per_host=2.0,  # 2 requests per second per host\n)\n\n# Each host has its own rate limit\nclient.get(\"http://api1.example.com/data\")  # Rate limited separately\nclient.get(\"http://api2.example.com/data\")  # Rate limited separately\nclient.get(\"http://api1.example.com/other\") # Shares limit with first request\n</code></pre>"},{"location":"rate-limiting/#non-blocking-mode","title":"Non-Blocking Mode","text":"<p>Raise an exception instead of waiting when rate limited:</p> <pre><code>from gakido import Client, RateLimitExceeded\n\nclient = Client(\n    rate_limit=1.0,\n    rate_limit_capacity=1.0,\n    rate_limit_blocking=False,  # Don't wait, raise exception\n)\n\ntry:\n    client.get(\"http://example.com\")  # First request OK\n    client.get(\"http://example.com\")  # Raises RateLimitExceeded\nexcept RateLimitExceeded as e:\n    print(f\"Rate limited! Retry after {e.retry_after:.2f}s\")\n</code></pre>"},{"location":"rate-limiting/#using-rate-limiters-directly","title":"Using Rate Limiters Directly","text":""},{"location":"rate-limiting/#token-bucket","title":"Token Bucket","text":"<p>The token bucket algorithm allows bursts up to capacity, then limits to the specified rate:</p> <pre><code>from gakido import TokenBucket, AsyncTokenBucket\n\n# Sync\nlimiter = TokenBucket(rate=10.0, capacity=20.0)\nlimiter.acquire()  # Get a token (blocks if none available)\n\n# With context manager\nwith limiter:\n    # Make your request here\n    pass\n\n# Async\nasync_limiter = AsyncTokenBucket(rate=10.0, capacity=20.0)\nawait async_limiter.acquire()\n\nasync with async_limiter:\n    # Make your async request here\n    pass\n</code></pre>"},{"location":"rate-limiting/#sliding-window-limiter","title":"Sliding Window Limiter","text":"<p>Strictly limit requests within a time window:</p> <pre><code>from gakido import SlidingWindowLimiter, AsyncSlidingWindowLimiter\n\n# Allow max 100 requests per minute\nlimiter = SlidingWindowLimiter(max_requests=100, window_seconds=60.0)\nlimiter.acquire()\n\n# Async version\nasync_limiter = AsyncSlidingWindowLimiter(max_requests=100, window_seconds=60.0)\nawait async_limiter.acquire()\n</code></pre>"},{"location":"rate-limiting/#per-host-rate-limiter","title":"Per-Host Rate Limiter","text":"<pre><code>from gakido import PerHostRateLimiter, AsyncPerHostRateLimiter\n\n# Sync\nlimiter = PerHostRateLimiter(rate=5.0, capacity=10.0)\nlimiter.acquire(\"api.example.com\")\nlimiter.acquire(\"other.example.com\")  # Separate limit\n\n# Async\nasync_limiter = AsyncPerHostRateLimiter(rate=5.0, capacity=10.0)\nawait async_limiter.acquire(\"api.example.com\")\n</code></pre>"},{"location":"rate-limiting/#decorators","title":"Decorators","text":"<p>Apply rate limiting to any function:</p> <pre><code>from gakido import rate_limited, arate_limited\n\n# Sync decorator\n@rate_limited(rate=5.0, capacity=10.0)\ndef make_api_call():\n    # Your code here\n    pass\n\n# Async decorator\n@arate_limited(rate=5.0, capacity=10.0)\nasync def async_api_call():\n    # Your async code here\n    pass\n\n# Non-blocking decorator\n@rate_limited(rate=1.0, blocking=False)\ndef strict_api_call():\n    # Raises RateLimitExceeded if rate exceeded\n    pass\n</code></pre>"},{"location":"rate-limiting/#combining-with-retry","title":"Combining with Retry","text":"<p>Rate limiting works seamlessly with retry logic:</p> <pre><code>from gakido import Client\n\nclient = Client(\n    # Rate limiting\n    rate_limit=10.0,\n    rate_limit_capacity=20.0,\n    # Retry on failures\n    max_retries=3,\n    retry_base_delay=1.0,\n)\n\n# Requests are rate limited, and failures are retried\nresponse = client.get(\"http://api.example.com/data\")\n</code></pre>"},{"location":"rate-limiting/#examples","title":"Examples","text":""},{"location":"rate-limiting/#api-with-strict-rate-limits","title":"API with Strict Rate Limits","text":"<pre><code>from gakido import AsyncClient\n\n# Twitter-like API: 300 requests per 15 minutes per endpoint\nclient = AsyncClient(\n    rate_limit=0.33,           # ~20 requests per minute\n    rate_limit_capacity=50.0,  # Allow some bursting\n)\n</code></pre>"},{"location":"rate-limiting/#web-scraping-with-politeness","title":"Web Scraping with Politeness","text":"<pre><code>from gakido import Client\n\n# Be polite to servers\nclient = Client(\n    rate_limit_per_host=1.0,  # 1 request per second per host\n    rate_limit_capacity=1.0,  # No bursting\n)\n</code></pre>"},{"location":"rate-limiting/#high-throughput-with-burst","title":"High-Throughput with Burst","text":"<pre><code>from gakido import AsyncClient\n\n# High throughput API with burst allowance\nclient = AsyncClient(\n    rate_limit=100.0,          # 100 requests per second sustained\n    rate_limit_capacity=500.0, # Allow bursts of 500\n)\n</code></pre>"},{"location":"rate-limiting/#best-practices","title":"Best Practices","text":"<ol> <li>Match API limits - Set rate limits to match your API provider's limits</li> <li>Use per-host limiting for web scraping to be polite to each server</li> <li>Allow reasonable bursts - Set capacity higher than rate for better UX</li> <li>Use non-blocking mode when you need to handle rate limits explicitly</li> <li>Combine with retry - Use retry for transient failures, rate limiting for throughput control</li> <li>Monitor rate limit exceptions - Track <code>RateLimitExceeded</code> to tune your limits</li> </ol>"},{"location":"retry/","title":"Retry with Exponential Backoff","text":"<p>gakido provides built-in retry functionality with exponential backoff for handling transient failures like network errors or server issues.</p>"},{"location":"retry/#features","title":"Features","text":"<ul> <li>Exponential backoff with configurable base delay and maximum delay</li> <li>Jitter to prevent thundering herd when many clients retry simultaneously</li> <li>Configurable retry conditions - retry on specific HTTP status codes and exception types</li> <li>Zero overhead when disabled (default)</li> <li>Works with both sync and async clients</li> </ul>"},{"location":"retry/#basic-usage","title":"Basic Usage","text":""},{"location":"retry/#sync-client","title":"Sync Client","text":"<pre><code>from gakido import Client\n\nclient = Client(\n    max_retries=3,           # Up to 3 retry attempts (4 total attempts)\n    retry_base_delay=0.5,    # Start with 0.5s delay\n    retry_max_delay=30.0,    # Cap delay at 30s\n    retry_jitter=True,       # Add random jitter\n)\n\ntry:\n    response = client.get(\"http://flaky.example.com\")\n    print(f\"Success: {response.status_code}\")\nexcept Exception as e:\n    print(f\"Failed after retries: {e}\")\n</code></pre>"},{"location":"retry/#async-client","title":"Async Client","text":"<pre><code>from gakido import AsyncClient\n\nasync_client = AsyncClient(\n    max_retries=2,\n    retry_base_delay=1.0,\n    retry_jitter=False,  # Predictable delays for testing\n)\n\ntry:\n    response = await async_client.get(\"http://api.example.com\")\n    print(f\"Success: {response.status_code}\")\nexcept Exception as e:\n    print(f\"Failed after retries: {e}\")\n</code></pre>"},{"location":"retry/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>max_retries</code> <code>int</code> <code>0</code> Maximum number of retry attempts (0 = disabled) <code>retry_base_delay</code> <code>float</code> <code>1.0</code> Initial delay in seconds for exponential backoff <code>retry_max_delay</code> <code>float</code> <code>60.0</code> Maximum delay in seconds <code>retry_jitter</code> <code>bool</code> <code>True</code> Whether to add random jitter to avoid thundering herd"},{"location":"retry/#retry-conditions","title":"Retry Conditions","text":""},{"location":"retry/#default-retryable-status-codes","title":"Default Retryable Status Codes","text":"<p>The following HTTP status codes trigger retries by default: - <code>408</code> - Request Timeout - <code>429</code> - Too Many Requests - <code>500</code> - Internal Server Error - <code>502</code> - Bad Gateway - <code>503</code> - Service Unavailable - <code>504</code> - Gateway Timeout - <code>507</code> - Insufficient Storage - <code>511</code> - Network Authentication Required</p>"},{"location":"retry/#default-retryable-exceptions","title":"Default Retryable Exceptions","text":"<p>The following exception types trigger retries by default: - <code>ConnectionError</code> - Network connection failures - <code>TimeoutError</code> - Request timeout - <code>OSError</code> - Operating system level errors</p>"},{"location":"retry/#using-retry-decorators-directly","title":"Using Retry Decorators Directly","text":"<p>You can also use the retry decorators directly on your own functions:</p> <pre><code>from gakido.backoff import retry_with_backoff, aretry_with_backoff\n\n# Sync decorator\n@retry_with_backoff(max_attempts=3, base_delay=0.1, jitter=False)\ndef flaky_operation():\n    # Your code here that might fail\n    pass\n\n# Async decorator\n@aretry_with_backoff(max_attempts=3, base_delay=0.1, jitter=False)\nasync def async_flaky_operation():\n    # Your async code here that might fail\n    pass\n</code></pre>"},{"location":"retry/#delay-calculation","title":"Delay Calculation","text":"<p>The delay between retries follows exponential backoff:</p> <pre><code>delay = min(base_delay * (2 ^ attempt), max_delay)\n</code></pre> <p>With jitter enabled (default), the delay is reduced to 50-100% of the calculated value to prevent synchronized retries across multiple clients.</p>"},{"location":"retry/#examples","title":"Examples","text":""},{"location":"retry/#handling-rate-limiting","title":"Handling Rate Limiting","text":"<pre><code>client = Client(\n    max_retries=5,\n    retry_base_delay=2.0,  # Start with 2s delay for rate limits\n    retry_jitter=True,\n)\n\n# Will retry on 429 Too Many Requests\nresponse = client.get(\"https://api.example.com/data\")\n</code></pre>"},{"location":"retry/#quick-retries-for-unstable-networks","title":"Quick Retries for Unstable Networks","text":"<pre><code>client = Client(\n    max_retries=2,\n    retry_base_delay=0.1,  # Quick retries\n    retry_max_delay=1.0,\n    retry_jitter=False,    # Predictable for debugging\n)\n</code></pre>"},{"location":"retry/#disabling-retry","title":"Disabling Retry","text":"<pre><code># Retry is disabled by default\nclient = Client()  # max_retries=0\n\n# Or explicitly disable\nclient = Client(max_retries=0)\n</code></pre>"},{"location":"retry/#best-practices","title":"Best Practices","text":"<ol> <li>Use jitter in production to prevent thundering herd</li> <li>Set reasonable max delays to avoid excessive wait times</li> <li>Monitor retry metrics to identify systemic issues</li> <li>Handle non-retryable errors appropriately (e.g., 404, 401)</li> <li>Test retry logic with controlled failures</li> </ol>"},{"location":"streaming/","title":"Streaming Responses","text":"<p>Gakido supports streaming responses to handle large downloads without loading the entire body into memory. This is essential for downloading large files, processing real-time data feeds, or handling chunked transfer encoding efficiently.</p>"},{"location":"streaming/#basic-usage","title":"Basic Usage","text":""},{"location":"streaming/#synchronous-streaming","title":"Synchronous Streaming","text":"<pre><code>from gakido import Client\n\nclient = Client()\n\n# Stream a large file\nwith client.stream(\"GET\", \"https://example.com/large-file.zip\") as response:\n    print(f\"Status: {response.status_code}\")\n\n    # Iterate over chunks\n    for chunk in response.iter_bytes(chunk_size=8192):\n        # Process each chunk (e.g., write to file, compute hash)\n        process(chunk)\n</code></pre>"},{"location":"streaming/#asynchronous-streaming","title":"Asynchronous Streaming","text":"<pre><code>import asyncio\nfrom gakido import AsyncClient\n\nasync def download():\n    client = AsyncClient()\n\n    async with await client.stream(\"GET\", \"https://example.com/large-file.zip\") as response:\n        async for chunk in response.aiter_bytes(chunk_size=8192):\n            process(chunk)\n\nasyncio.run(download())\n</code></pre>"},{"location":"streaming/#streamingresponse-api","title":"StreamingResponse API","text":""},{"location":"streaming/#properties","title":"Properties","text":"Property Type Description <code>status_code</code> <code>int</code> HTTP status code <code>reason</code> <code>str</code> HTTP reason phrase <code>http_version</code> <code>str</code> HTTP version (e.g., \"1.1\") <code>headers</code> <code>dict[str, str]</code> Response headers (case-insensitive keys) <code>raw_headers</code> <code>list[tuple[str, str]]</code> Headers in original order"},{"location":"streaming/#methods","title":"Methods","text":""},{"location":"streaming/#iter_byteschunk_size8192","title":"<code>iter_bytes(chunk_size=8192)</code>","text":"<p>Iterate over the response body in chunks.</p> <pre><code>with client.stream(\"GET\", url) as response:\n    for chunk in response.iter_bytes(chunk_size=16384):\n        file.write(chunk)\n</code></pre>"},{"location":"streaming/#iter_lineschunk_size8192-decodeutf-8","title":"<code>iter_lines(chunk_size=8192, decode=\"utf-8\")</code>","text":"<p>Iterate over the response body line by line.</p> <pre><code>with client.stream(\"GET\", url) as response:\n    for line in response.iter_lines():\n        print(line)  # Already decoded to str\n</code></pre>"},{"location":"streaming/#read","title":"<code>read()</code>","text":"<p>Read the entire response body into memory. Use with caution for large responses.</p> <pre><code>with client.stream(\"GET\", url) as response:\n    body = response.read()  # Returns bytes\n</code></pre>"},{"location":"streaming/#close","title":"<code>close()</code>","text":"<p>Close the response and release resources. Called automatically when using context manager.</p>"},{"location":"streaming/#asyncstreamingresponse-api","title":"AsyncStreamingResponse API","text":"<p>The async version has the same properties but uses async methods:</p> Method Description <code>aiter_bytes(chunk_size=8192)</code> Async iterate over chunks <code>aiter_lines(chunk_size=8192, decode=\"utf-8\")</code> Async iterate over lines <code>read()</code> Async read entire body <code>close()</code> Async close response"},{"location":"streaming/#examples","title":"Examples","text":""},{"location":"streaming/#download-to-file","title":"Download to File","text":"<pre><code>from gakido import Client\n\nclient = Client()\n\nwith client.stream(\"GET\", \"https://example.com/video.mp4\") as response:\n    with open(\"video.mp4\", \"wb\") as f:\n        for chunk in response.iter_bytes(chunk_size=65536):\n            f.write(chunk)\n</code></pre>"},{"location":"streaming/#process-json-lines-ndjson","title":"Process JSON Lines (NDJSON)","text":"<pre><code>import json\nfrom gakido import Client\n\nclient = Client()\n\nwith client.stream(\"GET\", \"https://api.example.com/events\") as response:\n    for line in response.iter_lines():\n        if line:\n            event = json.loads(line)\n            handle_event(event)\n</code></pre>"},{"location":"streaming/#progress-tracking","title":"Progress Tracking","text":"<pre><code>from gakido import Client\n\nclient = Client()\n\nwith client.stream(\"GET\", url) as response:\n    content_length = int(response.headers.get(\"content-length\", 0))\n    downloaded = 0\n\n    for chunk in response.iter_bytes():\n        downloaded += len(chunk)\n        if content_length:\n            progress = (downloaded / content_length) * 100\n            print(f\"\\rProgress: {progress:.1f}%\", end=\"\")\n</code></pre>"},{"location":"streaming/#async-concurrent-downloads","title":"Async Concurrent Downloads","text":"<pre><code>import asyncio\nfrom gakido import AsyncClient\n\nasync def download(client, url, filename):\n    async with await client.stream(\"GET\", url) as response:\n        with open(filename, \"wb\") as f:\n            async for chunk in response.aiter_bytes():\n                f.write(chunk)\n\nasync def main():\n    client = AsyncClient()\n\n    urls = [\n        (\"https://example.com/file1.zip\", \"file1.zip\"),\n        (\"https://example.com/file2.zip\", \"file2.zip\"),\n        (\"https://example.com/file3.zip\", \"file3.zip\"),\n    ]\n\n    await asyncio.gather(*[\n        download(client, url, filename)\n        for url, filename in urls\n    ])\n\nasyncio.run(main())\n</code></pre>"},{"location":"streaming/#streaming-with-decompression","title":"Streaming with Decompression","text":"<p>Gakido automatically decompresses gzip/deflate/brotli responses when <code>auto_decompress=True</code> (default). For streaming, compressed content is accumulated and decompressed at the end of each transfer-encoding chunk or content-length block.</p> <pre><code>client = Client(auto_decompress=True)  # Default\n\nwith client.stream(\"GET\", url) as response:\n    for chunk in response.iter_bytes():\n        # Chunks are automatically decompressed\n        process(chunk)\n</code></pre> <p>To receive raw compressed data:</p> <pre><code>client = Client(auto_decompress=False)\n\nwith client.stream(\"GET\", url) as response:\n    for chunk in response.iter_bytes():\n        # Raw compressed bytes\n        handle_compressed(chunk)\n</code></pre>"},{"location":"streaming/#important-notes","title":"Important Notes","text":"<ol> <li> <p>Always close the response: Use context managers (<code>with</code>/<code>async with</code>) to ensure resources are released.</p> </li> <li> <p>Connection not reused: Streaming responses do not return the connection to the pool. Each stream creates a new connection.</p> </li> <li> <p>Headers available immediately: Response headers are parsed before streaming begins, so you can check status codes and content-length before consuming the body.</p> </li> <li> <p>HTTP/2 limitation: Streaming is currently only supported for HTTP/1.1 in the sync client. The async client supports HTTP/1.1 streaming.</p> </li> <li> <p>Memory efficiency: For truly large files, use small chunk sizes and write directly to disk rather than accumulating in memory.</p> </li> </ol>"},{"location":"user-guide/","title":"User Guide","text":""},{"location":"user-guide/#sync-client","title":"Sync client","text":"<pre><code>from gakido import Client\n\nwith Client(impersonate=\"chrome_120\") as c:\n    r = c.get(\"https://httpbin.org/get\", headers={\"Accept-Encoding\": \"identity\"})\n    print(r.status_code, r.json())\n</code></pre>"},{"location":"user-guide/#post-multipart-upload","title":"POST / multipart upload","text":"<pre><code>files = {\"file\": (\"test.txt\", b\"hello\", \"text/plain\")}\ndata = {\"foo\": \"bar\"}\nwith Client() as c:\n    r = c.post(\"https://httpbin.org/post\", data=data, files=files)\n    print(r.json())\n</code></pre>"},{"location":"user-guide/#async-client","title":"Async client","text":"<pre><code>import asyncio\nfrom gakido.aio import AsyncClient\n\nasync def main():\n    async with AsyncClient(impersonate=\"chrome_120\") as c:\n        r = await c.get(\"https://httpbin.org/get\")\n        print(r.status_code)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/#profiles-impersonation","title":"Profiles &amp; impersonation","text":"<pre><code>from gakido import Client\n\nc = Client(impersonate=\"firefox_133\")\nr = c.get(\"https://tls.browserleaks.com/json\")\nprint(r.json().get(\"ja3_hash\"))\n</code></pre>"},{"location":"user-guide/#tls-overrides-ja3akamai-style","title":"TLS overrides (JA3/Akamai style)","text":"<pre><code>from gakido import Client, ExtraFingerprints\n\nja3_str = \"771,4866-4867-4865-49196,0-11-10,29,0\"\nextra_fp = ExtraFingerprints(alpn=[\"http/1.1\"])\n\nwith Client(\n    tls_configuration_options={\n        \"ja3_str\": ja3_str,\n        \"extra_fp\": extra_fp,\n    },\n    ja3={\"alpn\": [\"http/1.1\"]},\n) as c:\n    r = c.get(\"https://tls.browserleaks.com/json\", headers={\"Accept-Encoding\": \"identity\"})\n    print(r.json())\n</code></pre>"},{"location":"user-guide/#websocket","title":"WebSocket","text":"<pre><code>from gakido.websocket import WebSocket\n\nws = WebSocket.connect(\"echo.websocket.events\", 443, \"/\", headers=[], tls=True)\nws.send_text(\"hello\")\nopcode, payload = ws.recv()\nprint(payload.decode())\nws.close()\n</code></pre>"},{"location":"user-guide/#compression","title":"Compression","text":"<p>Gakido automatically handles response compression using profile-based content negotiation.</p>"},{"location":"user-guide/#default-behavior-auto_decompresstrue","title":"Default Behavior (auto_decompress=True)","text":"<pre><code>from gakido import Client\n\n# Uses profile's Accept-Encoding: \"gzip, deflate, br\"\n# Automatically decompresses responses\nwith Client(impersonate=\"chrome_120\") as c:\n    r = c.get(\"https://httpbin.org/gzip\")\n    print(r.json())  # Already decompressed\n</code></pre>"},{"location":"user-guide/#disable-compression","title":"Disable Compression","text":"<pre><code>from gakido import Client\n\n# Sends Accept-Encoding: identity\n# Returns raw, uncompressed responses\nwith Client(auto_decompress=False) as c:\n    r = c.get(\"https://example.com\")\n    print(r.content)  # Raw bytes\n</code></pre>"},{"location":"user-guide/#custom-accept-encoding","title":"Custom Accept-Encoding","text":"<pre><code>from gakido import Client\n\n# Override Accept-Encoding per request\nwith Client() as c:\n    r = c.get(\"https://example.com\", headers={\"Accept-Encoding\": \"gzip\"})\n</code></pre>"},{"location":"user-guide/#supported-encodings","title":"Supported Encodings","text":"<ul> <li>gzip - GNU zip compression</li> <li>deflate - zlib/deflate compression</li> <li>br - Brotli compression (included via <code>brotli</code> package)</li> </ul>"},{"location":"user-guide/#http3-quic","title":"HTTP/3 (QUIC)","text":"<p>HTTP/3 uses QUIC as the transport layer, providing improved performance for Cloudflare and CDN targets through 0-RTT connection establishment and multiplexed streams.</p>"},{"location":"user-guide/#installation","title":"Installation","text":"<pre><code>pip install gakido[h3]\n</code></pre>"},{"location":"user-guide/#basic-usage","title":"Basic Usage","text":"<pre><code>import asyncio\nfrom gakido import AsyncClient, is_http3_available\n\nasync def main():\n    # Check if HTTP/3 is available\n    if not is_http3_available():\n        print(\"Install HTTP/3 support: pip install gakido[h3]\")\n        return\n\n    async with AsyncClient(\n        impersonate=\"chrome_120\",\n        http3=True,           # Enable HTTP/3\n        http3_fallback=True,  # Fall back to H1/H2 if H3 fails\n        force_http1=False,    # Allow H2 as fallback\n    ) as client:\n        response = await client.get(\"https://cloudflare.com/cdn-cgi/trace\")\n        print(f\"HTTP/{response.http_version}: {response.status_code}\")\n        print(response.text)\n\nasyncio.run(main())\n</code></pre>"},{"location":"user-guide/#force-http3-for-specific-requests","title":"Force HTTP/3 for Specific Requests","text":"<pre><code>async with AsyncClient(http3=True) as client:\n    # Use client default (HTTP/3 with fallback)\n    r1 = await client.get(\"https://example.com\")\n\n    # Force HTTP/3 for this specific request (no fallback)\n    r2 = await client.request(\"GET\", \"https://cloudflare.com\", force_http3=True)\n</code></pre>"},{"location":"user-guide/#http3-benefits","title":"HTTP/3 Benefits","text":"<ul> <li>0-RTT Connection: Faster initial requests with QUIC's zero round-trip handshake</li> <li>No Head-of-Line Blocking: Multiplexed streams don't block each other</li> <li>Connection Migration: Survives network changes (WiFi to cellular)</li> <li>Built-in Encryption: TLS 1.3 integrated into the protocol</li> </ul>"}]}